Multiprocessing 启动方法已设置为 'spawn'。
正在创建任务集 (这可能需要一些时间)...
正在为 12x12 (density 0.1) 并行创建 20000 个环境...
创建 20000 个环境完成，耗时: 57.84s
正在为 16x16 (density 0.15) 并行创建 20000 个环境...
创建 20000 个环境完成，耗时: 59.43s
正在为 20x20 (density 0.2) 并行创建 20000 个环境...
创建 20000 个环境完成，耗时: 58.92s
正在为 24x24 (density 0.25) 并行创建 20000 个环境...
创建 20000 个环境完成，耗时: 58.56s
正在为 16x16 (density 0.3) 并行创建 20000 个环境...
创建 20000 个环境完成，耗时: 59.75s
任务集创建完毕。
[Main] 主进程使用 device: cuda
正在从 'reptile_drqn_meta_agent_interrupt.pth' 加载检查点...
成功加载检查点。将从 Iter 2072 和 Epsilon 0.9678 处恢复。
正在创建 14 个工作进程的进程池...
进程池创建完毕。
开始 Reptile 元学习训练 (共 35714 个批次, 14 个任务/批次)...
Meta Batch 150/35714 | Tasks 2100/500000 | Avg Batch Reward: 0.72 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.9674 | Total Train Steps: 66304 | Time/Batch: 11.93s | Avg Time/Batch: 14.72s
Meta Batch 160/35714 | Tasks 2240/500000 | Avg Batch Reward: 0.69 | Avg Batch Loss: 0.0016 | Meta Epsilon: 0.9653 | Total Train Steps: 70720 | Time/Batch: 13.20s | Avg Time/Batch: 12.43s
Meta Batch 170/35714 | Tasks 2380/500000 | Avg Batch Reward: 0.74 | Avg Batch Loss: 0.0015 | Meta Epsilon: 0.9631 | Total Train Steps: 75200 | Time/Batch: 11.91s | Avg Time/Batch: 12.74s
Meta Batch 180/35714 | Tasks 2520/500000 | Avg Batch Reward: 0.73 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.9609 | Total Train Steps: 79680 | Time/Batch: 12.11s | Avg Time/Batch: 12.51s
Meta Batch 190/35714 | Tasks 2660/500000 | Avg Batch Reward: 0.57 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.9588 | Total Train Steps: 84096 | Time/Batch: 13.01s | Avg Time/Batch: 12.57s
Meta Batch 200/35714 | Tasks 2800/500000 | Avg Batch Reward: 0.69 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.9567 | Total Train Steps: 88512 | Time/Batch: 10.65s | Avg Time/Batch: 11.77s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 2800) ---
Meta Batch 210/35714 | Tasks 2940/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.9546 | Total Train Steps: 92960 | Time/Batch: 11.66s | Avg Time/Batch: 12.47s
Meta Batch 220/35714 | Tasks 3080/500000 | Avg Batch Reward: 0.74 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.9525 | Total Train Steps: 97408 | Time/Batch: 11.22s | Avg Time/Batch: 12.66s
Meta Batch 230/35714 | Tasks 3220/500000 | Avg Batch Reward: 0.74 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.9503 | Total Train Steps: 101856 | Time/Batch: 11.04s | Avg Time/Batch: 12.38s
Meta Batch 240/35714 | Tasks 3360/500000 | Avg Batch Reward: 0.65 | Avg Batch Loss: 0.0015 | Meta Epsilon: 0.9483 | Total Train Steps: 106272 | Time/Batch: 13.46s | Avg Time/Batch: 12.79s
Meta Batch 250/35714 | Tasks 3500/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.9461 | Total Train Steps: 110752 | Time/Batch: 15.51s | Avg Time/Batch: 12.55s
Meta Batch 260/35714 | Tasks 3640/500000 | Avg Batch Reward: 0.63 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.9440 | Total Train Steps: 115232 | Time/Batch: 12.41s | Avg Time/Batch: 12.76s
Meta Batch 270/35714 | Tasks 3780/500000 | Avg Batch Reward: 0.67 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.9419 | Total Train Steps: 119680 | Time/Batch: 12.76s | Avg Time/Batch: 12.14s
Meta Batch 280/35714 | Tasks 3920/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.9398 | Total Train Steps: 124096 | Time/Batch: 11.88s | Avg Time/Batch: 11.70s
Meta Batch 290/35714 | Tasks 4060/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.9377 | Total Train Steps: 128544 | Time/Batch: 10.92s | Avg Time/Batch: 12.38s
Meta Batch 300/35714 | Tasks 4200/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.9357 | Total Train Steps: 132992 | Time/Batch: 14.05s | Avg Time/Batch: 12.45s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 4200) ---
Meta Batch 310/35714 | Tasks 4340/500000 | Avg Batch Reward: 0.65 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.9336 | Total Train Steps: 137408 | Time/Batch: 12.81s | Avg Time/Batch: 13.24s
Meta Batch 320/35714 | Tasks 4480/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.9315 | Total Train Steps: 141888 | Time/Batch: 12.90s | Avg Time/Batch: 12.32s
Meta Batch 330/35714 | Tasks 4620/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.9295 | Total Train Steps: 146304 | Time/Batch: 14.50s | Avg Time/Batch: 12.86s
Meta Batch 340/35714 | Tasks 4760/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.9274 | Total Train Steps: 150752 | Time/Batch: 12.61s | Avg Time/Batch: 12.63s
Meta Batch 350/35714 | Tasks 4900/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.9253 | Total Train Steps: 155200 | Time/Batch: 13.07s | Avg Time/Batch: 12.54s
Meta Batch 360/35714 | Tasks 5040/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.9233 | Total Train Steps: 159680 | Time/Batch: 10.90s | Avg Time/Batch: 12.87s
Meta Batch 370/35714 | Tasks 5180/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.9212 | Total Train Steps: 164128 | Time/Batch: 12.18s | Avg Time/Batch: 12.38s
Meta Batch 380/35714 | Tasks 5320/500000 | Avg Batch Reward: 0.78 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.9192 | Total Train Steps: 168544 | Time/Batch: 11.92s | Avg Time/Batch: 12.36s
Meta Batch 390/35714 | Tasks 5460/500000 | Avg Batch Reward: 0.75 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.9172 | Total Train Steps: 172960 | Time/Batch: 10.61s | Avg Time/Batch: 12.55s
Meta Batch 400/35714 | Tasks 5600/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.9152 | Total Train Steps: 177248 | Time/Batch: 15.01s | Avg Time/Batch: 12.15s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 5600) ---
Meta Batch 410/35714 | Tasks 5740/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.9132 | Total Train Steps: 181696 | Time/Batch: 11.49s | Avg Time/Batch: 13.61s
Meta Batch 420/35714 | Tasks 5880/500000 | Avg Batch Reward: 0.76 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.9111 | Total Train Steps: 186112 | Time/Batch: 11.05s | Avg Time/Batch: 12.36s
Meta Batch 430/35714 | Tasks 6020/500000 | Avg Batch Reward: 0.52 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.9091 | Total Train Steps: 190528 | Time/Batch: 13.06s | Avg Time/Batch: 12.51s
Meta Batch 440/35714 | Tasks 6160/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.9071 | Total Train Steps: 195008 | Time/Batch: 14.10s | Avg Time/Batch: 13.11s
Meta Batch 450/35714 | Tasks 6300/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.9051 | Total Train Steps: 199488 | Time/Batch: 13.89s | Avg Time/Batch: 13.10s
Meta Batch 460/35714 | Tasks 6440/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.9031 | Total Train Steps: 203904 | Time/Batch: 14.22s | Avg Time/Batch: 13.07s
Meta Batch 470/35714 | Tasks 6580/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.9011 | Total Train Steps: 208352 | Time/Batch: 13.47s | Avg Time/Batch: 13.06s
Meta Batch 480/35714 | Tasks 6720/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8991 | Total Train Steps: 212704 | Time/Batch: 14.67s | Avg Time/Batch: 12.89s
Meta Batch 490/35714 | Tasks 6860/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8971 | Total Train Steps: 217120 | Time/Batch: 11.75s | Avg Time/Batch: 12.96s
Meta Batch 500/35714 | Tasks 7000/500000 | Avg Batch Reward: 0.74 | Avg Batch Loss: 0.0016 | Meta Epsilon: 0.8952 | Total Train Steps: 221472 | Time/Batch: 12.95s | Avg Time/Batch: 12.89s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 7000) ---
Meta Batch 510/35714 | Tasks 7140/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8932 | Total Train Steps: 225888 | Time/Batch: 14.36s | Avg Time/Batch: 12.92s
Meta Batch 520/35714 | Tasks 7280/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8912 | Total Train Steps: 230336 | Time/Batch: 15.93s | Avg Time/Batch: 13.00s
Meta Batch 530/35714 | Tasks 7420/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.8892 | Total Train Steps: 234784 | Time/Batch: 14.64s | Avg Time/Batch: 13.18s
Meta Batch 540/35714 | Tasks 7560/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8873 | Total Train Steps: 239232 | Time/Batch: 12.68s | Avg Time/Batch: 12.87s
Meta Batch 550/35714 | Tasks 7700/500000 | Avg Batch Reward: 0.50 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8853 | Total Train Steps: 243712 | Time/Batch: 13.39s | Avg Time/Batch: 12.87s
Meta Batch 560/35714 | Tasks 7840/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8833 | Total Train Steps: 248160 | Time/Batch: 13.33s | Avg Time/Batch: 13.13s
Meta Batch 570/35714 | Tasks 7980/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8814 | Total Train Steps: 252512 | Time/Batch: 13.67s | Avg Time/Batch: 12.96s
Meta Batch 580/35714 | Tasks 8120/500000 | Avg Batch Reward: 0.63 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8795 | Total Train Steps: 256896 | Time/Batch: 11.54s | Avg Time/Batch: 12.47s
Meta Batch 590/35714 | Tasks 8260/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.8775 | Total Train Steps: 261312 | Time/Batch: 13.76s | Avg Time/Batch: 13.13s
Meta Batch 600/35714 | Tasks 8400/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8756 | Total Train Steps: 265696 | Time/Batch: 12.96s | Avg Time/Batch: 13.15s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 8400) ---
Meta Batch 610/35714 | Tasks 8540/500000 | Avg Batch Reward: 0.70 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.8737 | Total Train Steps: 270144 | Time/Batch: 10.99s | Avg Time/Batch: 13.06s
Meta Batch 620/35714 | Tasks 8680/500000 | Avg Batch Reward: 0.70 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8718 | Total Train Steps: 274464 | Time/Batch: 12.41s | Avg Time/Batch: 13.06s
Meta Batch 630/35714 | Tasks 8820/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.8698 | Total Train Steps: 278880 | Time/Batch: 12.56s | Avg Time/Batch: 13.21s
Meta Batch 640/35714 | Tasks 8960/500000 | Avg Batch Reward: 0.70 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8680 | Total Train Steps: 283232 | Time/Batch: 11.31s | Avg Time/Batch: 13.30s
Meta Batch 650/35714 | Tasks 9100/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.8660 | Total Train Steps: 287648 | Time/Batch: 11.94s | Avg Time/Batch: 12.95s
Meta Batch 660/35714 | Tasks 9240/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.8641 | Total Train Steps: 292096 | Time/Batch: 14.56s | Avg Time/Batch: 12.84s
Meta Batch 670/35714 | Tasks 9380/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8622 | Total Train Steps: 296480 | Time/Batch: 15.05s | Avg Time/Batch: 13.44s
Meta Batch 680/35714 | Tasks 9520/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8603 | Total Train Steps: 300896 | Time/Batch: 14.33s | Avg Time/Batch: 12.95s
Meta Batch 690/35714 | Tasks 9660/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8584 | Total Train Steps: 305376 | Time/Batch: 14.32s | Avg Time/Batch: 12.90s
Meta Batch 700/35714 | Tasks 9800/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8565 | Total Train Steps: 309792 | Time/Batch: 12.51s | Avg Time/Batch: 12.61s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 9800) ---
Meta Batch 710/35714 | Tasks 9940/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8546 | Total Train Steps: 314144 | Time/Batch: 14.47s | Avg Time/Batch: 13.48s
Meta Batch 720/35714 | Tasks 10080/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8528 | Total Train Steps: 318560 | Time/Batch: 13.69s | Avg Time/Batch: 13.57s
Meta Batch 730/35714 | Tasks 10220/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8509 | Total Train Steps: 322912 | Time/Batch: 14.40s | Avg Time/Batch: 12.95s
Meta Batch 740/35714 | Tasks 10360/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8490 | Total Train Steps: 327296 | Time/Batch: 11.90s | Avg Time/Batch: 13.41s
Meta Batch 750/35714 | Tasks 10500/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.8472 | Total Train Steps: 331616 | Time/Batch: 11.74s | Avg Time/Batch: 13.43s
Meta Batch 760/35714 | Tasks 10640/500000 | Avg Batch Reward: 0.57 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8453 | Total Train Steps: 336064 | Time/Batch: 13.77s | Avg Time/Batch: 14.10s
Meta Batch 770/35714 | Tasks 10780/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8434 | Total Train Steps: 340512 | Time/Batch: 13.86s | Avg Time/Batch: 13.19s
Meta Batch 780/35714 | Tasks 10920/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8416 | Total Train Steps: 344992 | Time/Batch: 13.89s | Avg Time/Batch: 13.35s
Meta Batch 790/35714 | Tasks 11060/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8397 | Total Train Steps: 349344 | Time/Batch: 16.22s | Avg Time/Batch: 13.62s
Meta Batch 800/35714 | Tasks 11200/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8379 | Total Train Steps: 353792 | Time/Batch: 12.22s | Avg Time/Batch: 13.45s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 11200) ---
Meta Batch 810/35714 | Tasks 11340/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8360 | Total Train Steps: 358272 | Time/Batch: 13.40s | Avg Time/Batch: 13.23s
Meta Batch 820/35714 | Tasks 11480/500000 | Avg Batch Reward: 0.65 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8341 | Total Train Steps: 362688 | Time/Batch: 12.03s | Avg Time/Batch: 12.30s
Meta Batch 830/35714 | Tasks 11620/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8323 | Total Train Steps: 367104 | Time/Batch: 14.18s | Avg Time/Batch: 13.03s
Meta Batch 840/35714 | Tasks 11760/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.8305 | Total Train Steps: 371520 | Time/Batch: 13.31s | Avg Time/Batch: 13.22s
Meta Batch 850/35714 | Tasks 11900/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.8286 | Total Train Steps: 375936 | Time/Batch: 11.25s | Avg Time/Batch: 12.85s
Meta Batch 860/35714 | Tasks 12040/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8268 | Total Train Steps: 380352 | Time/Batch: 13.26s | Avg Time/Batch: 13.02s
Meta Batch 870/35714 | Tasks 12180/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.8250 | Total Train Steps: 384800 | Time/Batch: 14.08s | Avg Time/Batch: 13.43s
Meta Batch 880/35714 | Tasks 12320/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8232 | Total Train Steps: 389120 | Time/Batch: 13.49s | Avg Time/Batch: 13.20s
Meta Batch 890/35714 | Tasks 12460/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8214 | Total Train Steps: 393600 | Time/Batch: 13.04s | Avg Time/Batch: 13.28s
Meta Batch 900/35714 | Tasks 12600/500000 | Avg Batch Reward: 0.63 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.8196 | Total Train Steps: 397952 | Time/Batch: 13.77s | Avg Time/Batch: 12.80s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 12600) ---
Meta Batch 910/35714 | Tasks 12740/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8178 | Total Train Steps: 402272 | Time/Batch: 12.44s | Avg Time/Batch: 12.60s
Meta Batch 920/35714 | Tasks 12880/500000 | Avg Batch Reward: 0.63 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8160 | Total Train Steps: 406624 | Time/Batch: 12.40s | Avg Time/Batch: 13.39s
Meta Batch 930/35714 | Tasks 13020/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.8142 | Total Train Steps: 410976 | Time/Batch: 11.98s | Avg Time/Batch: 12.96s
Meta Batch 940/35714 | Tasks 13160/500000 | Avg Batch Reward: 0.50 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8124 | Total Train Steps: 415424 | Time/Batch: 14.86s | Avg Time/Batch: 13.67s
Meta Batch 950/35714 | Tasks 13300/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8106 | Total Train Steps: 419872 | Time/Batch: 14.56s | Avg Time/Batch: 13.94s
Meta Batch 960/35714 | Tasks 13440/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8088 | Total Train Steps: 424352 | Time/Batch: 14.46s | Avg Time/Batch: 13.60s
Meta Batch 970/35714 | Tasks 13580/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.8070 | Total Train Steps: 428768 | Time/Batch: 13.26s | Avg Time/Batch: 13.18s
Meta Batch 980/35714 | Tasks 13720/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.8052 | Total Train Steps: 433216 | Time/Batch: 11.81s | Avg Time/Batch: 13.63s
Meta Batch 990/35714 | Tasks 13860/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.8035 | Total Train Steps: 437632 | Time/Batch: 13.52s | Avg Time/Batch: 13.48s
Meta Batch 1000/35714 | Tasks 14000/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.8017 | Total Train Steps: 442080 | Time/Batch: 13.57s | Avg Time/Batch: 13.40s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 14000) ---
Meta Batch 1010/35714 | Tasks 14140/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0020 | Meta Epsilon: 0.7999 | Total Train Steps: 446496 | Time/Batch: 10.44s | Avg Time/Batch: 12.90s
Meta Batch 1020/35714 | Tasks 14280/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7982 | Total Train Steps: 450848 | Time/Batch: 12.82s | Avg Time/Batch: 12.51s
Meta Batch 1030/35714 | Tasks 14420/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7964 | Total Train Steps: 455328 | Time/Batch: 12.54s | Avg Time/Batch: 13.61s
Meta Batch 1040/35714 | Tasks 14560/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7946 | Total Train Steps: 459776 | Time/Batch: 12.96s | Avg Time/Batch: 13.18s
Meta Batch 1050/35714 | Tasks 14700/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7929 | Total Train Steps: 464224 | Time/Batch: 15.28s | Avg Time/Batch: 14.51s
Meta Batch 1060/35714 | Tasks 14840/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.7911 | Total Train Steps: 468640 | Time/Batch: 14.66s | Avg Time/Batch: 13.94s
Meta Batch 1070/35714 | Tasks 14980/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7893 | Total Train Steps: 473120 | Time/Batch: 13.15s | Avg Time/Batch: 13.19s
Meta Batch 1080/35714 | Tasks 15120/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.7876 | Total Train Steps: 477568 | Time/Batch: 11.72s | Avg Time/Batch: 13.63s
Meta Batch 1090/35714 | Tasks 15260/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7859 | Total Train Steps: 481920 | Time/Batch: 11.54s | Avg Time/Batch: 12.97s
Meta Batch 1100/35714 | Tasks 15400/500000 | Avg Batch Reward: 0.72 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.7841 | Total Train Steps: 486336 | Time/Batch: 11.17s | Avg Time/Batch: 13.06s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 15400) ---
Meta Batch 1110/35714 | Tasks 15540/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0016 | Meta Epsilon: 0.7824 | Total Train Steps: 490816 | Time/Batch: 12.09s | Avg Time/Batch: 12.95s
Meta Batch 1120/35714 | Tasks 15680/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.7807 | Total Train Steps: 495200 | Time/Batch: 13.59s | Avg Time/Batch: 13.28s
Meta Batch 1130/35714 | Tasks 15820/500000 | Avg Batch Reward: 0.52 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.7790 | Total Train Steps: 499616 | Time/Batch: 12.75s | Avg Time/Batch: 13.36s
Meta Batch 1140/35714 | Tasks 15960/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.7772 | Total Train Steps: 504032 | Time/Batch: 12.08s | Avg Time/Batch: 13.23s
Meta Batch 1150/35714 | Tasks 16100/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.7755 | Total Train Steps: 508384 | Time/Batch: 14.09s | Avg Time/Batch: 13.04s
Meta Batch 1160/35714 | Tasks 16240/500000 | Avg Batch Reward: 0.64 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7738 | Total Train Steps: 512832 | Time/Batch: 10.59s | Avg Time/Batch: 13.88s
Meta Batch 1170/35714 | Tasks 16380/500000 | Avg Batch Reward: 0.70 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.7721 | Total Train Steps: 517216 | Time/Batch: 10.96s | Avg Time/Batch: 13.71s
Meta Batch 1180/35714 | Tasks 16520/500000 | Avg Batch Reward: 0.76 | Avg Batch Loss: 0.0015 | Meta Epsilon: 0.7704 | Total Train Steps: 521632 | Time/Batch: 11.07s | Avg Time/Batch: 13.37s
Meta Batch 1190/35714 | Tasks 16660/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7687 | Total Train Steps: 525984 | Time/Batch: 10.06s | Avg Time/Batch: 13.19s
Meta Batch 1200/35714 | Tasks 16800/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7670 | Total Train Steps: 530464 | Time/Batch: 13.40s | Avg Time/Batch: 13.90s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 16800) ---
Meta Batch 1210/35714 | Tasks 16940/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7654 | Total Train Steps: 534752 | Time/Batch: 11.35s | Avg Time/Batch: 13.41s
Meta Batch 1220/35714 | Tasks 17080/500000 | Avg Batch Reward: 0.43 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7637 | Total Train Steps: 539136 | Time/Batch: 13.74s | Avg Time/Batch: 12.72s
Meta Batch 1230/35714 | Tasks 17220/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7620 | Total Train Steps: 543520 | Time/Batch: 13.37s | Avg Time/Batch: 13.71s
Meta Batch 1240/35714 | Tasks 17360/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7603 | Total Train Steps: 547968 | Time/Batch: 13.44s | Avg Time/Batch: 14.16s
Meta Batch 1250/35714 | Tasks 17500/500000 | Avg Batch Reward: 0.77 | Avg Batch Loss: 0.0017 | Meta Epsilon: 0.7587 | Total Train Steps: 552384 | Time/Batch: 9.58s | Avg Time/Batch: 13.07s
Meta Batch 1260/35714 | Tasks 17640/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7570 | Total Train Steps: 556800 | Time/Batch: 14.49s | Avg Time/Batch: 13.59s
Meta Batch 1270/35714 | Tasks 17780/500000 | Avg Batch Reward: 0.57 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7553 | Total Train Steps: 561248 | Time/Batch: 12.91s | Avg Time/Batch: 13.94s
Meta Batch 1280/35714 | Tasks 17920/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.7536 | Total Train Steps: 565696 | Time/Batch: 14.10s | Avg Time/Batch: 13.76s
Meta Batch 1290/35714 | Tasks 18060/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.7519 | Total Train Steps: 570176 | Time/Batch: 14.34s | Avg Time/Batch: 13.38s
Meta Batch 1300/35714 | Tasks 18200/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7503 | Total Train Steps: 574624 | Time/Batch: 12.10s | Avg Time/Batch: 12.85s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 18200) ---
Meta Batch 1310/35714 | Tasks 18340/500000 | Avg Batch Reward: 0.43 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7486 | Total Train Steps: 579040 | Time/Batch: 15.13s | Avg Time/Batch: 14.06s
Meta Batch 1320/35714 | Tasks 18480/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7470 | Total Train Steps: 583424 | Time/Batch: 12.18s | Avg Time/Batch: 12.36s
Meta Batch 1330/35714 | Tasks 18620/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.7453 | Total Train Steps: 587808 | Time/Batch: 11.85s | Avg Time/Batch: 13.25s
Meta Batch 1340/35714 | Tasks 18760/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.7437 | Total Train Steps: 592224 | Time/Batch: 13.38s | Avg Time/Batch: 13.01s
Meta Batch 1350/35714 | Tasks 18900/500000 | Avg Batch Reward: 0.50 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7421 | Total Train Steps: 596608 | Time/Batch: 14.85s | Avg Time/Batch: 13.86s
Meta Batch 1360/35714 | Tasks 19040/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7404 | Total Train Steps: 601024 | Time/Batch: 12.25s | Avg Time/Batch: 13.62s
Meta Batch 1370/35714 | Tasks 19180/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.7388 | Total Train Steps: 605472 | Time/Batch: 15.82s | Avg Time/Batch: 14.32s
Meta Batch 1380/35714 | Tasks 19320/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7372 | Total Train Steps: 609920 | Time/Batch: 13.17s | Avg Time/Batch: 14.08s
Meta Batch 1390/35714 | Tasks 19460/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7356 | Total Train Steps: 614208 | Time/Batch: 14.01s | Avg Time/Batch: 13.15s
Meta Batch 1400/35714 | Tasks 19600/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7339 | Total Train Steps: 618656 | Time/Batch: 14.65s | Avg Time/Batch: 13.40s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 19600) ---
Meta Batch 1410/35714 | Tasks 19740/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7323 | Total Train Steps: 623072 | Time/Batch: 15.60s | Avg Time/Batch: 13.11s
Meta Batch 1420/35714 | Tasks 19880/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7307 | Total Train Steps: 627488 | Time/Batch: 13.67s | Avg Time/Batch: 13.06s
Meta Batch 1430/35714 | Tasks 20020/500000 | Avg Batch Reward: 0.55 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7291 | Total Train Steps: 631936 | Time/Batch: 11.56s | Avg Time/Batch: 13.77s
Meta Batch 1440/35714 | Tasks 20160/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7275 | Total Train Steps: 636352 | Time/Batch: 13.28s | Avg Time/Batch: 13.42s
Meta Batch 1450/35714 | Tasks 20300/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7259 | Total Train Steps: 640736 | Time/Batch: 13.58s | Avg Time/Batch: 12.78s
Meta Batch 1460/35714 | Tasks 20440/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7243 | Total Train Steps: 645184 | Time/Batch: 13.66s | Avg Time/Batch: 13.22s
Meta Batch 1470/35714 | Tasks 20580/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.7227 | Total Train Steps: 649632 | Time/Batch: 13.67s | Avg Time/Batch: 13.39s
Meta Batch 1480/35714 | Tasks 20720/500000 | Avg Batch Reward: 0.55 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.7211 | Total Train Steps: 654016 | Time/Batch: 12.66s | Avg Time/Batch: 13.20s
Meta Batch 1490/35714 | Tasks 20860/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7195 | Total Train Steps: 658432 | Time/Batch: 14.71s | Avg Time/Batch: 13.99s
Meta Batch 1500/35714 | Tasks 21000/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7179 | Total Train Steps: 662848 | Time/Batch: 14.32s | Avg Time/Batch: 13.64s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 21000) ---
Meta Batch 1510/35714 | Tasks 21140/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.7163 | Total Train Steps: 667264 | Time/Batch: 12.60s | Avg Time/Batch: 13.52s
Meta Batch 1520/35714 | Tasks 21280/500000 | Avg Batch Reward: 0.74 | Avg Batch Loss: 0.0017 | Meta Epsilon: 0.7147 | Total Train Steps: 671712 | Time/Batch: 11.07s | Avg Time/Batch: 12.86s
Meta Batch 1530/35714 | Tasks 21420/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0018 | Meta Epsilon: 0.7131 | Total Train Steps: 676160 | Time/Batch: 12.81s | Avg Time/Batch: 13.35s
Meta Batch 1540/35714 | Tasks 21560/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.7116 | Total Train Steps: 680608 | Time/Batch: 15.20s | Avg Time/Batch: 13.40s
Meta Batch 1550/35714 | Tasks 21700/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7100 | Total Train Steps: 685056 | Time/Batch: 14.50s | Avg Time/Batch: 12.93s
Meta Batch 1560/35714 | Tasks 21840/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7084 | Total Train Steps: 689504 | Time/Batch: 13.64s | Avg Time/Batch: 13.96s
Meta Batch 1570/35714 | Tasks 21980/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.7069 | Total Train Steps: 693856 | Time/Batch: 12.69s | Avg Time/Batch: 12.67s
Meta Batch 1580/35714 | Tasks 22120/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7053 | Total Train Steps: 698208 | Time/Batch: 15.08s | Avg Time/Batch: 13.44s
Meta Batch 1590/35714 | Tasks 22260/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.7037 | Total Train Steps: 702688 | Time/Batch: 12.71s | Avg Time/Batch: 13.61s
Meta Batch 1600/35714 | Tasks 22400/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.7022 | Total Train Steps: 707040 | Time/Batch: 14.44s | Avg Time/Batch: 13.27s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 22400) ---
Meta Batch 1610/35714 | Tasks 22540/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.7007 | Total Train Steps: 711424 | Time/Batch: 11.62s | Avg Time/Batch: 12.64s
Meta Batch 1620/35714 | Tasks 22680/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6991 | Total Train Steps: 715872 | Time/Batch: 12.64s | Avg Time/Batch: 13.06s
Meta Batch 1630/35714 | Tasks 22820/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.6976 | Total Train Steps: 720288 | Time/Batch: 12.16s | Avg Time/Batch: 13.61s
Meta Batch 1640/35714 | Tasks 22960/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6960 | Total Train Steps: 724704 | Time/Batch: 12.19s | Avg Time/Batch: 13.36s
Meta Batch 1650/35714 | Tasks 23100/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6945 | Total Train Steps: 729120 | Time/Batch: 13.46s | Avg Time/Batch: 13.25s
Meta Batch 1660/35714 | Tasks 23240/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6930 | Total Train Steps: 733568 | Time/Batch: 13.71s | Avg Time/Batch: 13.62s
Meta Batch 1670/35714 | Tasks 23380/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6914 | Total Train Steps: 737952 | Time/Batch: 13.40s | Avg Time/Batch: 13.19s
Meta Batch 1680/35714 | Tasks 23520/500000 | Avg Batch Reward: 0.69 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.6899 | Total Train Steps: 742368 | Time/Batch: 12.64s | Avg Time/Batch: 13.08s
Meta Batch 1690/35714 | Tasks 23660/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.6884 | Total Train Steps: 746784 | Time/Batch: 13.40s | Avg Time/Batch: 13.37s
Meta Batch 1700/35714 | Tasks 23800/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6869 | Total Train Steps: 751264 | Time/Batch: 13.93s | Avg Time/Batch: 13.51s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 23800) ---
Meta Batch 1710/35714 | Tasks 23940/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6853 | Total Train Steps: 755712 | Time/Batch: 14.27s | Avg Time/Batch: 13.77s
Meta Batch 1720/35714 | Tasks 24080/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6838 | Total Train Steps: 760064 | Time/Batch: 12.94s | Avg Time/Batch: 13.13s
Meta Batch 1730/35714 | Tasks 24220/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.6823 | Total Train Steps: 764544 | Time/Batch: 13.31s | Avg Time/Batch: 13.41s
Meta Batch 1740/35714 | Tasks 24360/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.6808 | Total Train Steps: 768928 | Time/Batch: 13.44s | Avg Time/Batch: 13.62s
Meta Batch 1750/35714 | Tasks 24500/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6793 | Total Train Steps: 773344 | Time/Batch: 14.87s | Avg Time/Batch: 12.96s
Meta Batch 1760/35714 | Tasks 24640/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6778 | Total Train Steps: 777728 | Time/Batch: 13.88s | Avg Time/Batch: 13.81s
Meta Batch 1770/35714 | Tasks 24780/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6764 | Total Train Steps: 782080 | Time/Batch: 12.50s | Avg Time/Batch: 13.22s
Meta Batch 1780/35714 | Tasks 24920/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6749 | Total Train Steps: 786496 | Time/Batch: 14.83s | Avg Time/Batch: 13.48s
Meta Batch 1790/35714 | Tasks 25060/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6734 | Total Train Steps: 790944 | Time/Batch: 14.00s | Avg Time/Batch: 13.55s
Meta Batch 1800/35714 | Tasks 25200/500000 | Avg Batch Reward: 0.65 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6719 | Total Train Steps: 795360 | Time/Batch: 10.84s | Avg Time/Batch: 13.41s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 25200) ---
Meta Batch 1810/35714 | Tasks 25340/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.6704 | Total Train Steps: 799680 | Time/Batch: 13.44s | Avg Time/Batch: 13.64s
Meta Batch 1820/35714 | Tasks 25480/500000 | Avg Batch Reward: 0.69 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6689 | Total Train Steps: 804128 | Time/Batch: 13.84s | Avg Time/Batch: 14.19s
Meta Batch 1830/35714 | Tasks 25620/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6675 | Total Train Steps: 808544 | Time/Batch: 14.90s | Avg Time/Batch: 12.72s
Meta Batch 1840/35714 | Tasks 25760/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6660 | Total Train Steps: 812800 | Time/Batch: 12.24s | Avg Time/Batch: 12.41s
Meta Batch 1850/35714 | Tasks 25900/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6646 | Total Train Steps: 817184 | Time/Batch: 10.24s | Avg Time/Batch: 12.93s
Meta Batch 1860/35714 | Tasks 26040/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6631 | Total Train Steps: 821632 | Time/Batch: 12.74s | Avg Time/Batch: 14.01s
Meta Batch 1870/35714 | Tasks 26180/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6616 | Total Train Steps: 826048 | Time/Batch: 11.38s | Avg Time/Batch: 13.46s
Meta Batch 1880/35714 | Tasks 26320/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6602 | Total Train Steps: 830464 | Time/Batch: 12.07s | Avg Time/Batch: 13.41s
Meta Batch 1890/35714 | Tasks 26460/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6587 | Total Train Steps: 834848 | Time/Batch: 12.39s | Avg Time/Batch: 13.82s
Meta Batch 1900/35714 | Tasks 26600/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6573 | Total Train Steps: 839296 | Time/Batch: 12.95s | Avg Time/Batch: 14.10s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 26600) ---
Meta Batch 1910/35714 | Tasks 26740/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6558 | Total Train Steps: 843680 | Time/Batch: 14.40s | Avg Time/Batch: 14.20s
Meta Batch 1920/35714 | Tasks 26880/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6544 | Total Train Steps: 848000 | Time/Batch: 11.86s | Avg Time/Batch: 13.05s
Meta Batch 1930/35714 | Tasks 27020/500000 | Avg Batch Reward: 0.50 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6530 | Total Train Steps: 852320 | Time/Batch: 11.55s | Avg Time/Batch: 12.78s
Meta Batch 1940/35714 | Tasks 27160/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6516 | Total Train Steps: 856736 | Time/Batch: 14.09s | Avg Time/Batch: 13.50s
Meta Batch 1950/35714 | Tasks 27300/500000 | Avg Batch Reward: 0.57 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6501 | Total Train Steps: 861184 | Time/Batch: 13.23s | Avg Time/Batch: 14.10s
Meta Batch 1960/35714 | Tasks 27440/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6487 | Total Train Steps: 865600 | Time/Batch: 14.29s | Avg Time/Batch: 13.56s
Meta Batch 1970/35714 | Tasks 27580/500000 | Avg Batch Reward: 0.62 | Avg Batch Loss: 0.0015 | Meta Epsilon: 0.6473 | Total Train Steps: 870016 | Time/Batch: 13.37s | Avg Time/Batch: 13.57s
Meta Batch 1980/35714 | Tasks 27720/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.6458 | Total Train Steps: 874432 | Time/Batch: 13.62s | Avg Time/Batch: 12.97s
Meta Batch 1990/35714 | Tasks 27860/500000 | Avg Batch Reward: 0.50 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.6444 | Total Train Steps: 878784 | Time/Batch: 13.87s | Avg Time/Batch: 13.10s
Meta Batch 2000/35714 | Tasks 28000/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6430 | Total Train Steps: 883168 | Time/Batch: 16.70s | Avg Time/Batch: 13.98s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 28000) ---
Meta Batch 2010/35714 | Tasks 28140/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6416 | Total Train Steps: 887552 | Time/Batch: 13.87s | Avg Time/Batch: 13.68s
Meta Batch 2020/35714 | Tasks 28280/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.6402 | Total Train Steps: 891968 | Time/Batch: 13.83s | Avg Time/Batch: 13.52s
Meta Batch 2030/35714 | Tasks 28420/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.6388 | Total Train Steps: 896384 | Time/Batch: 12.20s | Avg Time/Batch: 13.44s
Meta Batch 2040/35714 | Tasks 28560/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.6374 | Total Train Steps: 900768 | Time/Batch: 13.12s | Avg Time/Batch: 13.45s
Meta Batch 2050/35714 | Tasks 28700/500000 | Avg Batch Reward: 0.71 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.6360 | Total Train Steps: 905088 | Time/Batch: 10.71s | Avg Time/Batch: 13.44s
Meta Batch 2060/35714 | Tasks 28840/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.6346 | Total Train Steps: 909504 | Time/Batch: 14.98s | Avg Time/Batch: 13.89s
Meta Batch 2070/35714 | Tasks 28980/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6332 | Total Train Steps: 913984 | Time/Batch: 12.33s | Avg Time/Batch: 13.96s
Meta Batch 2080/35714 | Tasks 29120/500000 | Avg Batch Reward: 0.66 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6318 | Total Train Steps: 918368 | Time/Batch: 12.13s | Avg Time/Batch: 12.86s
Meta Batch 2090/35714 | Tasks 29260/500000 | Avg Batch Reward: 0.60 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6305 | Total Train Steps: 922624 | Time/Batch: 11.95s | Avg Time/Batch: 12.57s
Meta Batch 2100/35714 | Tasks 29400/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.6291 | Total Train Steps: 926912 | Time/Batch: 12.98s | Avg Time/Batch: 14.04s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 29400) ---
Meta Batch 2110/35714 | Tasks 29540/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6277 | Total Train Steps: 931360 | Time/Batch: 14.68s | Avg Time/Batch: 13.79s
Meta Batch 2120/35714 | Tasks 29680/500000 | Avg Batch Reward: 0.67 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.6264 | Total Train Steps: 935616 | Time/Batch: 10.34s | Avg Time/Batch: 13.32s
Meta Batch 2130/35714 | Tasks 29820/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.6250 | Total Train Steps: 940000 | Time/Batch: 12.08s | Avg Time/Batch: 13.43s
Meta Batch 2140/35714 | Tasks 29960/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6236 | Total Train Steps: 944416 | Time/Batch: 13.82s | Avg Time/Batch: 13.61s
Meta Batch 2150/35714 | Tasks 30100/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.6222 | Total Train Steps: 948832 | Time/Batch: 15.11s | Avg Time/Batch: 13.10s
Meta Batch 2160/35714 | Tasks 30240/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.6209 | Total Train Steps: 953280 | Time/Batch: 12.70s | Avg Time/Batch: 13.75s
Meta Batch 2170/35714 | Tasks 30380/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.6195 | Total Train Steps: 957696 | Time/Batch: 15.32s | Avg Time/Batch: 13.52s
Meta Batch 2180/35714 | Tasks 30520/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.6182 | Total Train Steps: 961984 | Time/Batch: 11.77s | Avg Time/Batch: 13.08s
Meta Batch 2190/35714 | Tasks 30660/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6168 | Total Train Steps: 966368 | Time/Batch: 15.01s | Avg Time/Batch: 12.98s
Meta Batch 2200/35714 | Tasks 30800/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.6154 | Total Train Steps: 970816 | Time/Batch: 16.31s | Avg Time/Batch: 14.04s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 30800) ---
Meta Batch 2210/35714 | Tasks 30940/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6141 | Total Train Steps: 975136 | Time/Batch: 15.17s | Avg Time/Batch: 13.26s
Meta Batch 2220/35714 | Tasks 31080/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6128 | Total Train Steps: 979520 | Time/Batch: 13.46s | Avg Time/Batch: 13.46s
Meta Batch 2230/35714 | Tasks 31220/500000 | Avg Batch Reward: 0.55 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.6114 | Total Train Steps: 984000 | Time/Batch: 14.32s | Avg Time/Batch: 14.10s
Meta Batch 2240/35714 | Tasks 31360/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.6100 | Total Train Steps: 988448 | Time/Batch: 14.96s | Avg Time/Batch: 13.50s
Meta Batch 2250/35714 | Tasks 31500/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.6087 | Total Train Steps: 992832 | Time/Batch: 12.58s | Avg Time/Batch: 13.18s
Meta Batch 2260/35714 | Tasks 31640/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6074 | Total Train Steps: 997184 | Time/Batch: 13.52s | Avg Time/Batch: 13.11s
Meta Batch 2270/35714 | Tasks 31780/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6060 | Total Train Steps: 1001632 | Time/Batch: 12.89s | Avg Time/Batch: 13.37s
Meta Batch 2280/35714 | Tasks 31920/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.6047 | Total Train Steps: 1006016 | Time/Batch: 15.60s | Avg Time/Batch: 14.27s
Meta Batch 2290/35714 | Tasks 32060/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.6034 | Total Train Steps: 1010432 | Time/Batch: 15.04s | Avg Time/Batch: 14.07s
Meta Batch 2300/35714 | Tasks 32200/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.6021 | Total Train Steps: 1014784 | Time/Batch: 13.80s | Avg Time/Batch: 13.53s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 32200) ---
Meta Batch 2310/35714 | Tasks 32340/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.6007 | Total Train Steps: 1019264 | Time/Batch: 15.25s | Avg Time/Batch: 13.53s
Meta Batch 2320/35714 | Tasks 32480/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5994 | Total Train Steps: 1023712 | Time/Batch: 13.39s | Avg Time/Batch: 13.32s
Meta Batch 2330/35714 | Tasks 32620/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.5981 | Total Train Steps: 1028160 | Time/Batch: 16.14s | Avg Time/Batch: 13.87s
Meta Batch 2340/35714 | Tasks 32760/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5967 | Total Train Steps: 1032640 | Time/Batch: 14.75s | Avg Time/Batch: 13.56s
Meta Batch 2350/35714 | Tasks 32900/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5954 | Total Train Steps: 1037088 | Time/Batch: 11.53s | Avg Time/Batch: 13.44s
Meta Batch 2360/35714 | Tasks 33040/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5941 | Total Train Steps: 1041568 | Time/Batch: 14.10s | Avg Time/Batch: 14.45s
Meta Batch 2370/35714 | Tasks 33180/500000 | Avg Batch Reward: 0.57 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5927 | Total Train Steps: 1045984 | Time/Batch: 13.72s | Avg Time/Batch: 13.75s
Meta Batch 2380/35714 | Tasks 33320/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5914 | Total Train Steps: 1050400 | Time/Batch: 12.10s | Avg Time/Batch: 13.10s
Meta Batch 2390/35714 | Tasks 33460/500000 | Avg Batch Reward: 0.32 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5901 | Total Train Steps: 1054848 | Time/Batch: 15.50s | Avg Time/Batch: 13.68s
Meta Batch 2400/35714 | Tasks 33600/500000 | Avg Batch Reward: 0.25 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5888 | Total Train Steps: 1059264 | Time/Batch: 14.58s | Avg Time/Batch: 13.35s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 33600) ---
Meta Batch 2410/35714 | Tasks 33740/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5875 | Total Train Steps: 1063648 | Time/Batch: 12.20s | Avg Time/Batch: 13.56s
Meta Batch 2420/35714 | Tasks 33880/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5862 | Total Train Steps: 1068064 | Time/Batch: 11.30s | Avg Time/Batch: 13.02s
Meta Batch 2430/35714 | Tasks 34020/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5849 | Total Train Steps: 1072544 | Time/Batch: 12.89s | Avg Time/Batch: 14.03s
Meta Batch 2440/35714 | Tasks 34160/500000 | Avg Batch Reward: 0.70 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5837 | Total Train Steps: 1076864 | Time/Batch: 12.15s | Avg Time/Batch: 13.51s
Meta Batch 2450/35714 | Tasks 34300/500000 | Avg Batch Reward: 0.25 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.5824 | Total Train Steps: 1081280 | Time/Batch: 13.91s | Avg Time/Batch: 13.64s
Meta Batch 2460/35714 | Tasks 34440/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5811 | Total Train Steps: 1085600 | Time/Batch: 14.97s | Avg Time/Batch: 13.81s
Meta Batch 2470/35714 | Tasks 34580/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5798 | Total Train Steps: 1089984 | Time/Batch: 15.34s | Avg Time/Batch: 13.43s
Meta Batch 2480/35714 | Tasks 34720/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5786 | Total Train Steps: 1094208 | Time/Batch: 12.70s | Avg Time/Batch: 13.52s
Meta Batch 2490/35714 | Tasks 34860/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5773 | Total Train Steps: 1098624 | Time/Batch: 15.50s | Avg Time/Batch: 14.37s
Meta Batch 2500/35714 | Tasks 35000/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.5761 | Total Train Steps: 1103104 | Time/Batch: 15.35s | Avg Time/Batch: 13.35s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 35000) ---
Meta Batch 2510/35714 | Tasks 35140/500000 | Avg Batch Reward: 0.55 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5748 | Total Train Steps: 1107520 | Time/Batch: 13.55s | Avg Time/Batch: 14.14s
Meta Batch 2520/35714 | Tasks 35280/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5735 | Total Train Steps: 1111936 | Time/Batch: 14.55s | Avg Time/Batch: 13.70s
Meta Batch 2530/35714 | Tasks 35420/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5723 | Total Train Steps: 1116192 | Time/Batch: 14.73s | Avg Time/Batch: 13.03s
Meta Batch 2540/35714 | Tasks 35560/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.5710 | Total Train Steps: 1120608 | Time/Batch: 13.56s | Avg Time/Batch: 13.32s
Meta Batch 2550/35714 | Tasks 35700/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5698 | Total Train Steps: 1125088 | Time/Batch: 14.97s | Avg Time/Batch: 14.04s
Meta Batch 2560/35714 | Tasks 35840/500000 | Avg Batch Reward: 0.30 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.5685 | Total Train Steps: 1129472 | Time/Batch: 16.35s | Avg Time/Batch: 13.82s
Meta Batch 2570/35714 | Tasks 35980/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.5673 | Total Train Steps: 1133856 | Time/Batch: 12.64s | Avg Time/Batch: 13.15s
Meta Batch 2580/35714 | Tasks 36120/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5660 | Total Train Steps: 1138272 | Time/Batch: 13.39s | Avg Time/Batch: 14.25s
Meta Batch 2590/35714 | Tasks 36260/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5648 | Total Train Steps: 1142528 | Time/Batch: 12.91s | Avg Time/Batch: 13.00s
Meta Batch 2600/35714 | Tasks 36400/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5636 | Total Train Steps: 1146848 | Time/Batch: 12.78s | Avg Time/Batch: 13.46s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 36400) ---
Meta Batch 2610/35714 | Tasks 36540/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5624 | Total Train Steps: 1151232 | Time/Batch: 13.59s | Avg Time/Batch: 14.42s
Meta Batch 2620/35714 | Tasks 36680/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5611 | Total Train Steps: 1155680 | Time/Batch: 12.62s | Avg Time/Batch: 13.28s
Meta Batch 2630/35714 | Tasks 36820/500000 | Avg Batch Reward: 0.70 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5599 | Total Train Steps: 1160128 | Time/Batch: 11.47s | Avg Time/Batch: 13.32s
Meta Batch 2640/35714 | Tasks 36960/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.5586 | Total Train Steps: 1164480 | Time/Batch: 12.50s | Avg Time/Batch: 13.91s
Meta Batch 2650/35714 | Tasks 37100/500000 | Avg Batch Reward: 0.30 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.5574 | Total Train Steps: 1168960 | Time/Batch: 15.38s | Avg Time/Batch: 14.19s
Meta Batch 2660/35714 | Tasks 37240/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5562 | Total Train Steps: 1173376 | Time/Batch: 12.22s | Avg Time/Batch: 14.03s
Meta Batch 2670/35714 | Tasks 37380/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.5550 | Total Train Steps: 1177728 | Time/Batch: 13.11s | Avg Time/Batch: 13.78s
Meta Batch 2680/35714 | Tasks 37520/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5538 | Total Train Steps: 1182048 | Time/Batch: 15.06s | Avg Time/Batch: 13.56s
Meta Batch 2690/35714 | Tasks 37660/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5525 | Total Train Steps: 1186432 | Time/Batch: 13.82s | Avg Time/Batch: 13.99s
Meta Batch 2700/35714 | Tasks 37800/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5513 | Total Train Steps: 1190880 | Time/Batch: 12.91s | Avg Time/Batch: 14.40s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 37800) ---
Meta Batch 2710/35714 | Tasks 37940/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5501 | Total Train Steps: 1195328 | Time/Batch: 13.25s | Avg Time/Batch: 13.55s
Meta Batch 2720/35714 | Tasks 38080/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5489 | Total Train Steps: 1199744 | Time/Batch: 14.89s | Avg Time/Batch: 13.42s
Meta Batch 2730/35714 | Tasks 38220/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5477 | Total Train Steps: 1204128 | Time/Batch: 14.93s | Avg Time/Batch: 13.87s
Meta Batch 2740/35714 | Tasks 38360/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5465 | Total Train Steps: 1208512 | Time/Batch: 13.73s | Avg Time/Batch: 14.20s
Meta Batch 2750/35714 | Tasks 38500/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5453 | Total Train Steps: 1212960 | Time/Batch: 14.78s | Avg Time/Batch: 13.90s
Meta Batch 2760/35714 | Tasks 38640/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.5441 | Total Train Steps: 1217280 | Time/Batch: 12.90s | Avg Time/Batch: 13.67s
Meta Batch 2770/35714 | Tasks 38780/500000 | Avg Batch Reward: 0.55 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.5429 | Total Train Steps: 1221664 | Time/Batch: 12.86s | Avg Time/Batch: 13.50s
Meta Batch 2780/35714 | Tasks 38920/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5417 | Total Train Steps: 1226016 | Time/Batch: 11.48s | Avg Time/Batch: 13.25s
Meta Batch 2790/35714 | Tasks 39060/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5405 | Total Train Steps: 1230464 | Time/Batch: 13.79s | Avg Time/Batch: 14.45s
Meta Batch 2800/35714 | Tasks 39200/500000 | Avg Batch Reward: 0.52 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5393 | Total Train Steps: 1234848 | Time/Batch: 14.40s | Avg Time/Batch: 14.49s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 39200) ---
Meta Batch 2810/35714 | Tasks 39340/500000 | Avg Batch Reward: 0.43 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5382 | Total Train Steps: 1239232 | Time/Batch: 15.89s | Avg Time/Batch: 14.14s
Meta Batch 2820/35714 | Tasks 39480/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5370 | Total Train Steps: 1243584 | Time/Batch: 12.76s | Avg Time/Batch: 14.11s
Meta Batch 2830/35714 | Tasks 39620/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5358 | Total Train Steps: 1248000 | Time/Batch: 14.14s | Avg Time/Batch: 14.29s
Meta Batch 2840/35714 | Tasks 39760/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5346 | Total Train Steps: 1252416 | Time/Batch: 14.96s | Avg Time/Batch: 13.91s
Meta Batch 2850/35714 | Tasks 39900/500000 | Avg Batch Reward: 0.22 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.5335 | Total Train Steps: 1256736 | Time/Batch: 14.03s | Avg Time/Batch: 13.38s
Meta Batch 2860/35714 | Tasks 40040/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.5323 | Total Train Steps: 1261056 | Time/Batch: 13.65s | Avg Time/Batch: 14.03s
Meta Batch 2870/35714 | Tasks 40180/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5311 | Total Train Steps: 1265472 | Time/Batch: 14.50s | Avg Time/Batch: 13.87s
Meta Batch 2880/35714 | Tasks 40320/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.5300 | Total Train Steps: 1269728 | Time/Batch: 12.83s | Avg Time/Batch: 13.69s
Meta Batch 2890/35714 | Tasks 40460/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5288 | Total Train Steps: 1274112 | Time/Batch: 13.15s | Avg Time/Batch: 13.86s
Meta Batch 2900/35714 | Tasks 40600/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5277 | Total Train Steps: 1278464 | Time/Batch: 14.93s | Avg Time/Batch: 14.27s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 40600) ---
Meta Batch 2910/35714 | Tasks 40740/500000 | Avg Batch Reward: 0.52 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5265 | Total Train Steps: 1282880 | Time/Batch: 12.27s | Avg Time/Batch: 14.08s
Meta Batch 2920/35714 | Tasks 40880/500000 | Avg Batch Reward: 0.35 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5254 | Total Train Steps: 1287328 | Time/Batch: 15.00s | Avg Time/Batch: 14.63s
Meta Batch 2930/35714 | Tasks 41020/500000 | Avg Batch Reward: 0.30 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5242 | Total Train Steps: 1291712 | Time/Batch: 14.62s | Avg Time/Batch: 13.50s
Meta Batch 2940/35714 | Tasks 41160/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5231 | Total Train Steps: 1296064 | Time/Batch: 13.30s | Avg Time/Batch: 13.85s
Meta Batch 2950/35714 | Tasks 41300/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5219 | Total Train Steps: 1300512 | Time/Batch: 14.49s | Avg Time/Batch: 14.48s
Meta Batch 2960/35714 | Tasks 41440/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5208 | Total Train Steps: 1304960 | Time/Batch: 14.10s | Avg Time/Batch: 14.79s
Meta Batch 2970/35714 | Tasks 41580/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5196 | Total Train Steps: 1309280 | Time/Batch: 14.50s | Avg Time/Batch: 14.18s
Meta Batch 2980/35714 | Tasks 41720/500000 | Avg Batch Reward: 0.54 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5185 | Total Train Steps: 1313568 | Time/Batch: 11.69s | Avg Time/Batch: 13.39s
Meta Batch 2990/35714 | Tasks 41860/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5174 | Total Train Steps: 1318048 | Time/Batch: 15.32s | Avg Time/Batch: 14.29s
Meta Batch 3000/35714 | Tasks 42000/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5162 | Total Train Steps: 1322368 | Time/Batch: 13.13s | Avg Time/Batch: 13.45s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 42000) ---
Meta Batch 3010/35714 | Tasks 42140/500000 | Avg Batch Reward: 0.56 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5151 | Total Train Steps: 1326720 | Time/Batch: 14.18s | Avg Time/Batch: 14.49s
Meta Batch 3020/35714 | Tasks 42280/500000 | Avg Batch Reward: 0.61 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.5140 | Total Train Steps: 1331136 | Time/Batch: 13.27s | Avg Time/Batch: 14.01s
Meta Batch 3030/35714 | Tasks 42420/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.5128 | Total Train Steps: 1335584 | Time/Batch: 14.46s | Avg Time/Batch: 14.25s
Meta Batch 3040/35714 | Tasks 42560/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5117 | Total Train Steps: 1339904 | Time/Batch: 12.77s | Avg Time/Batch: 13.29s
Meta Batch 3050/35714 | Tasks 42700/500000 | Avg Batch Reward: 0.35 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.5106 | Total Train Steps: 1344320 | Time/Batch: 13.43s | Avg Time/Batch: 13.96s
Meta Batch 3060/35714 | Tasks 42840/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5095 | Total Train Steps: 1348736 | Time/Batch: 14.93s | Avg Time/Batch: 14.58s
Meta Batch 3070/35714 | Tasks 42980/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.5083 | Total Train Steps: 1353184 | Time/Batch: 12.16s | Avg Time/Batch: 13.83s
Meta Batch 3080/35714 | Tasks 43120/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5072 | Total Train Steps: 1357568 | Time/Batch: 16.28s | Avg Time/Batch: 14.21s
Meta Batch 3090/35714 | Tasks 43260/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.5061 | Total Train Steps: 1361984 | Time/Batch: 15.66s | Avg Time/Batch: 14.37s
Meta Batch 3100/35714 | Tasks 43400/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5050 | Total Train Steps: 1366464 | Time/Batch: 14.63s | Avg Time/Batch: 14.24s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 43400) ---
Meta Batch 3110/35714 | Tasks 43540/500000 | Avg Batch Reward: 0.27 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.5039 | Total Train Steps: 1370848 | Time/Batch: 15.39s | Avg Time/Batch: 13.84s
Meta Batch 3120/35714 | Tasks 43680/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.5028 | Total Train Steps: 1375168 | Time/Batch: 14.49s | Avg Time/Batch: 13.66s
Meta Batch 3130/35714 | Tasks 43820/500000 | Avg Batch Reward: 0.47 | Avg Batch Loss: 0.0013 | Meta Epsilon: 0.5017 | Total Train Steps: 1379584 | Time/Batch: 13.31s | Avg Time/Batch: 14.63s
Meta Batch 3140/35714 | Tasks 43960/500000 | Avg Batch Reward: 0.59 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.5006 | Total Train Steps: 1383936 | Time/Batch: 11.05s | Avg Time/Batch: 13.95s
Meta Batch 3150/35714 | Tasks 44100/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4995 | Total Train Steps: 1388320 | Time/Batch: 13.79s | Avg Time/Batch: 13.86s
Meta Batch 3160/35714 | Tasks 44240/500000 | Avg Batch Reward: 0.62 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.4984 | Total Train Steps: 1392768 | Time/Batch: 12.34s | Avg Time/Batch: 13.80s
Meta Batch 3170/35714 | Tasks 44380/500000 | Avg Batch Reward: 0.25 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4973 | Total Train Steps: 1397184 | Time/Batch: 14.23s | Avg Time/Batch: 14.77s
Meta Batch 3180/35714 | Tasks 44520/500000 | Avg Batch Reward: 0.21 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4962 | Total Train Steps: 1401536 | Time/Batch: 15.23s | Avg Time/Batch: 14.26s
Meta Batch 3190/35714 | Tasks 44660/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4951 | Total Train Steps: 1405952 | Time/Batch: 14.97s | Avg Time/Batch: 14.32s
Meta Batch 3200/35714 | Tasks 44800/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4940 | Total Train Steps: 1410368 | Time/Batch: 14.19s | Avg Time/Batch: 14.26s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 44800) ---
Meta Batch 3210/35714 | Tasks 44940/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4929 | Total Train Steps: 1414784 | Time/Batch: 13.86s | Avg Time/Batch: 13.91s
Meta Batch 3220/35714 | Tasks 45080/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4919 | Total Train Steps: 1419008 | Time/Batch: 14.40s | Avg Time/Batch: 14.20s
Meta Batch 3230/35714 | Tasks 45220/500000 | Avg Batch Reward: 0.25 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4908 | Total Train Steps: 1423360 | Time/Batch: 14.40s | Avg Time/Batch: 13.56s
Meta Batch 3240/35714 | Tasks 45360/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4898 | Total Train Steps: 1427712 | Time/Batch: 14.99s | Avg Time/Batch: 13.93s
Meta Batch 3250/35714 | Tasks 45500/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4887 | Total Train Steps: 1432032 | Time/Batch: 11.85s | Avg Time/Batch: 14.00s
Meta Batch 3260/35714 | Tasks 45640/500000 | Avg Batch Reward: 0.25 | Avg Batch Loss: 0.0002 | Meta Epsilon: 0.4876 | Total Train Steps: 1436384 | Time/Batch: 14.58s | Avg Time/Batch: 14.51s
Meta Batch 3270/35714 | Tasks 45780/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4866 | Total Train Steps: 1440736 | Time/Batch: 14.77s | Avg Time/Batch: 14.38s
Meta Batch 3280/35714 | Tasks 45920/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.4855 | Total Train Steps: 1445152 | Time/Batch: 13.21s | Avg Time/Batch: 14.00s
Meta Batch 3290/35714 | Tasks 46060/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4845 | Total Train Steps: 1449376 | Time/Batch: 14.06s | Avg Time/Batch: 14.60s
Meta Batch 3300/35714 | Tasks 46200/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4834 | Total Train Steps: 1453696 | Time/Batch: 13.85s | Avg Time/Batch: 13.50s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 46200) ---
Meta Batch 3310/35714 | Tasks 46340/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.4824 | Total Train Steps: 1458048 | Time/Batch: 13.44s | Avg Time/Batch: 14.42s
Meta Batch 3320/35714 | Tasks 46480/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4813 | Total Train Steps: 1462336 | Time/Batch: 14.05s | Avg Time/Batch: 14.22s
Meta Batch 3330/35714 | Tasks 46620/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.4803 | Total Train Steps: 1466624 | Time/Batch: 11.53s | Avg Time/Batch: 14.09s
Meta Batch 3340/35714 | Tasks 46760/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.4792 | Total Train Steps: 1471072 | Time/Batch: 13.19s | Avg Time/Batch: 14.57s
Meta Batch 3350/35714 | Tasks 46900/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4782 | Total Train Steps: 1475456 | Time/Batch: 16.13s | Avg Time/Batch: 14.53s
Meta Batch 3360/35714 | Tasks 47040/500000 | Avg Batch Reward: 0.19 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4772 | Total Train Steps: 1479776 | Time/Batch: 16.04s | Avg Time/Batch: 14.02s
Meta Batch 3370/35714 | Tasks 47180/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4761 | Total Train Steps: 1484160 | Time/Batch: 11.49s | Avg Time/Batch: 13.92s
Meta Batch 3380/35714 | Tasks 47320/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4751 | Total Train Steps: 1488608 | Time/Batch: 15.00s | Avg Time/Batch: 14.55s
Meta Batch 3390/35714 | Tasks 47460/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.4740 | Total Train Steps: 1493088 | Time/Batch: 14.64s | Avg Time/Batch: 14.68s
Meta Batch 3400/35714 | Tasks 47600/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4730 | Total Train Steps: 1497440 | Time/Batch: 14.25s | Avg Time/Batch: 14.86s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 47600) ---
Meta Batch 3410/35714 | Tasks 47740/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0015 | Meta Epsilon: 0.4719 | Total Train Steps: 1501792 | Time/Batch: 13.36s | Avg Time/Batch: 14.26s
Meta Batch 3420/35714 | Tasks 47880/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4709 | Total Train Steps: 1506144 | Time/Batch: 14.12s | Avg Time/Batch: 13.95s
Meta Batch 3430/35714 | Tasks 48020/500000 | Avg Batch Reward: 0.29 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4699 | Total Train Steps: 1510560 | Time/Batch: 13.33s | Avg Time/Batch: 15.17s
Meta Batch 3440/35714 | Tasks 48160/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4689 | Total Train Steps: 1514944 | Time/Batch: 14.98s | Avg Time/Batch: 14.67s
Meta Batch 3450/35714 | Tasks 48300/500000 | Avg Batch Reward: 0.48 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4678 | Total Train Steps: 1519232 | Time/Batch: 14.09s | Avg Time/Batch: 14.73s
Meta Batch 3460/35714 | Tasks 48440/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4668 | Total Train Steps: 1523616 | Time/Batch: 13.50s | Avg Time/Batch: 13.96s
Meta Batch 3470/35714 | Tasks 48580/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.4658 | Total Train Steps: 1528032 | Time/Batch: 14.53s | Avg Time/Batch: 14.45s
Meta Batch 3480/35714 | Tasks 48720/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.4648 | Total Train Steps: 1532480 | Time/Batch: 14.14s | Avg Time/Batch: 14.74s
Meta Batch 3490/35714 | Tasks 48860/500000 | Avg Batch Reward: 0.58 | Avg Batch Loss: 0.0014 | Meta Epsilon: 0.4637 | Total Train Steps: 1536896 | Time/Batch: 12.04s | Avg Time/Batch: 13.90s
Meta Batch 3500/35714 | Tasks 49000/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.4627 | Total Train Steps: 1541280 | Time/Batch: 12.41s | Avg Time/Batch: 14.77s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 49000) ---
Meta Batch 3510/35714 | Tasks 49140/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4617 | Total Train Steps: 1545600 | Time/Batch: 12.74s | Avg Time/Batch: 14.16s
Meta Batch 3520/35714 | Tasks 49280/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4607 | Total Train Steps: 1549952 | Time/Batch: 13.25s | Avg Time/Batch: 13.80s
Meta Batch 3530/35714 | Tasks 49420/500000 | Avg Batch Reward: 0.57 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4597 | Total Train Steps: 1554240 | Time/Batch: 11.66s | Avg Time/Batch: 14.48s
Meta Batch 3540/35714 | Tasks 49560/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4587 | Total Train Steps: 1558656 | Time/Batch: 12.15s | Avg Time/Batch: 14.21s
Meta Batch 3550/35714 | Tasks 49700/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0017 | Meta Epsilon: 0.4577 | Total Train Steps: 1563104 | Time/Batch: 15.07s | Avg Time/Batch: 14.32s
Meta Batch 3560/35714 | Tasks 49840/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4567 | Total Train Steps: 1567552 | Time/Batch: 14.30s | Avg Time/Batch: 14.60s
Meta Batch 3570/35714 | Tasks 49980/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4557 | Total Train Steps: 1571936 | Time/Batch: 15.99s | Avg Time/Batch: 14.06s
Meta Batch 3580/35714 | Tasks 50120/500000 | Avg Batch Reward: 0.21 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4547 | Total Train Steps: 1576320 | Time/Batch: 14.37s | Avg Time/Batch: 14.55s
Meta Batch 3590/35714 | Tasks 50260/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4537 | Total Train Steps: 1580640 | Time/Batch: 13.30s | Avg Time/Batch: 14.60s
Meta Batch 3600/35714 | Tasks 50400/500000 | Avg Batch Reward: 0.28 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4527 | Total Train Steps: 1584928 | Time/Batch: 14.91s | Avg Time/Batch: 14.49s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 50400) ---
Meta Batch 3610/35714 | Tasks 50540/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4517 | Total Train Steps: 1589376 | Time/Batch: 16.09s | Avg Time/Batch: 14.48s
Meta Batch 3620/35714 | Tasks 50680/500000 | Avg Batch Reward: 0.46 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4507 | Total Train Steps: 1593824 | Time/Batch: 14.46s | Avg Time/Batch: 15.26s
Meta Batch 3630/35714 | Tasks 50820/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4497 | Total Train Steps: 1598240 | Time/Batch: 12.78s | Avg Time/Batch: 14.50s
Meta Batch 3640/35714 | Tasks 50960/500000 | Avg Batch Reward: 0.28 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4487 | Total Train Steps: 1602656 | Time/Batch: 16.21s | Avg Time/Batch: 14.75s
Meta Batch 3650/35714 | Tasks 51100/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4477 | Total Train Steps: 1607072 | Time/Batch: 16.73s | Avg Time/Batch: 14.47s
Meta Batch 3660/35714 | Tasks 51240/500000 | Avg Batch Reward: 0.51 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4468 | Total Train Steps: 1611424 | Time/Batch: 12.87s | Avg Time/Batch: 14.23s
Meta Batch 3670/35714 | Tasks 51380/500000 | Avg Batch Reward: 0.33 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4458 | Total Train Steps: 1615872 | Time/Batch: 15.30s | Avg Time/Batch: 14.92s
Meta Batch 3680/35714 | Tasks 51520/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4448 | Total Train Steps: 1620288 | Time/Batch: 15.15s | Avg Time/Batch: 14.18s
Meta Batch 3690/35714 | Tasks 51660/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4438 | Total Train Steps: 1624768 | Time/Batch: 13.94s | Avg Time/Batch: 14.68s
Meta Batch 3700/35714 | Tasks 51800/500000 | Avg Batch Reward: 0.23 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4428 | Total Train Steps: 1629152 | Time/Batch: 16.30s | Avg Time/Batch: 14.64s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 51800) ---
Meta Batch 3710/35714 | Tasks 51940/500000 | Avg Batch Reward: 0.35 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4418 | Total Train Steps: 1633600 | Time/Batch: 14.40s | Avg Time/Batch: 14.75s
Meta Batch 3720/35714 | Tasks 52080/500000 | Avg Batch Reward: 0.33 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4409 | Total Train Steps: 1637984 | Time/Batch: 13.85s | Avg Time/Batch: 14.47s
Meta Batch 3730/35714 | Tasks 52220/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4399 | Total Train Steps: 1642336 | Time/Batch: 13.37s | Avg Time/Batch: 13.71s
Meta Batch 3740/35714 | Tasks 52360/500000 | Avg Batch Reward: 0.27 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4390 | Total Train Steps: 1646656 | Time/Batch: 15.56s | Avg Time/Batch: 14.43s
Meta Batch 3750/35714 | Tasks 52500/500000 | Avg Batch Reward: 0.30 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4380 | Total Train Steps: 1650976 | Time/Batch: 14.08s | Avg Time/Batch: 14.22s
Meta Batch 3760/35714 | Tasks 52640/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4371 | Total Train Steps: 1655264 | Time/Batch: 13.25s | Avg Time/Batch: 14.13s
Meta Batch 3770/35714 | Tasks 52780/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4361 | Total Train Steps: 1659712 | Time/Batch: 15.93s | Avg Time/Batch: 15.62s
Meta Batch 3780/35714 | Tasks 52920/500000 | Avg Batch Reward: 0.42 | Avg Batch Loss: 0.0017 | Meta Epsilon: 0.4352 | Total Train Steps: 1664128 | Time/Batch: 14.58s | Avg Time/Batch: 14.92s
Meta Batch 3790/35714 | Tasks 53060/500000 | Avg Batch Reward: 0.29 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4342 | Total Train Steps: 1668576 | Time/Batch: 15.33s | Avg Time/Batch: 14.42s
Meta Batch 3800/35714 | Tasks 53200/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4332 | Total Train Steps: 1672928 | Time/Batch: 14.85s | Avg Time/Batch: 14.78s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 53200) ---
Meta Batch 3810/35714 | Tasks 53340/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0010 | Meta Epsilon: 0.4323 | Total Train Steps: 1677312 | Time/Batch: 13.78s | Avg Time/Batch: 14.83s
Meta Batch 3820/35714 | Tasks 53480/500000 | Avg Batch Reward: 0.21 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4313 | Total Train Steps: 1681792 | Time/Batch: 14.92s | Avg Time/Batch: 14.06s
Meta Batch 3830/35714 | Tasks 53620/500000 | Avg Batch Reward: 0.53 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4304 | Total Train Steps: 1686240 | Time/Batch: 14.17s | Avg Time/Batch: 14.72s
Meta Batch 3840/35714 | Tasks 53760/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4294 | Total Train Steps: 1690592 | Time/Batch: 14.33s | Avg Time/Batch: 15.09s
Meta Batch 3850/35714 | Tasks 53900/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4285 | Total Train Steps: 1694912 | Time/Batch: 13.07s | Avg Time/Batch: 14.24s
Meta Batch 3860/35714 | Tasks 54040/500000 | Avg Batch Reward: 0.49 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.4276 | Total Train Steps: 1699296 | Time/Batch: 14.51s | Avg Time/Batch: 14.60s
Meta Batch 3870/35714 | Tasks 54180/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0012 | Meta Epsilon: 0.4266 | Total Train Steps: 1703584 | Time/Batch: 13.86s | Avg Time/Batch: 15.27s
Meta Batch 3880/35714 | Tasks 54320/500000 | Avg Batch Reward: 0.20 | Avg Batch Loss: 0.0002 | Meta Epsilon: 0.4257 | Total Train Steps: 1708064 | Time/Batch: 15.90s | Avg Time/Batch: 14.88s
Meta Batch 3890/35714 | Tasks 54460/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4248 | Total Train Steps: 1712480 | Time/Batch: 16.85s | Avg Time/Batch: 14.74s
Meta Batch 3900/35714 | Tasks 54600/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4238 | Total Train Steps: 1716800 | Time/Batch: 16.22s | Avg Time/Batch: 14.59s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 54600) ---
Meta Batch 3910/35714 | Tasks 54740/500000 | Avg Batch Reward: 0.37 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4229 | Total Train Steps: 1721216 | Time/Batch: 15.18s | Avg Time/Batch: 15.91s
Meta Batch 3920/35714 | Tasks 54880/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4220 | Total Train Steps: 1725536 | Time/Batch: 13.52s | Avg Time/Batch: 13.70s
Meta Batch 3930/35714 | Tasks 55020/500000 | Avg Batch Reward: 0.45 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4211 | Total Train Steps: 1729888 | Time/Batch: 13.08s | Avg Time/Batch: 13.52s
Meta Batch 3940/35714 | Tasks 55160/500000 | Avg Batch Reward: 0.32 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4201 | Total Train Steps: 1734304 | Time/Batch: 15.21s | Avg Time/Batch: 14.94s
Meta Batch 3950/35714 | Tasks 55300/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4192 | Total Train Steps: 1738592 | Time/Batch: 16.07s | Avg Time/Batch: 14.69s
Meta Batch 3960/35714 | Tasks 55440/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4183 | Total Train Steps: 1742944 | Time/Batch: 14.06s | Avg Time/Batch: 14.69s
Meta Batch 3970/35714 | Tasks 55580/500000 | Avg Batch Reward: 0.40 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4174 | Total Train Steps: 1747360 | Time/Batch: 12.14s | Avg Time/Batch: 14.63s
Meta Batch 3980/35714 | Tasks 55720/500000 | Avg Batch Reward: 0.41 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.4165 | Total Train Steps: 1751776 | Time/Batch: 15.11s | Avg Time/Batch: 14.03s
Meta Batch 3990/35714 | Tasks 55860/500000 | Avg Batch Reward: 0.29 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4156 | Total Train Steps: 1756064 | Time/Batch: 15.33s | Avg Time/Batch: 14.20s
Meta Batch 4000/35714 | Tasks 56000/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0009 | Meta Epsilon: 0.4147 | Total Train Steps: 1760288 | Time/Batch: 13.56s | Avg Time/Batch: 14.20s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 56000) ---
Meta Batch 4010/35714 | Tasks 56140/500000 | Avg Batch Reward: 0.26 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4138 | Total Train Steps: 1764576 | Time/Batch: 14.68s | Avg Time/Batch: 13.27s
Meta Batch 4020/35714 | Tasks 56280/500000 | Avg Batch Reward: 0.28 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4129 | Total Train Steps: 1768992 | Time/Batch: 15.27s | Avg Time/Batch: 14.41s
Meta Batch 4030/35714 | Tasks 56420/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4120 | Total Train Steps: 1773344 | Time/Batch: 13.18s | Avg Time/Batch: 14.48s
Meta Batch 4040/35714 | Tasks 56560/500000 | Avg Batch Reward: 0.38 | Avg Batch Loss: 0.0011 | Meta Epsilon: 0.4111 | Total Train Steps: 1777728 | Time/Batch: 13.47s | Avg Time/Batch: 14.02s
Meta Batch 4050/35714 | Tasks 56700/500000 | Avg Batch Reward: 0.33 | Avg Batch Loss: 0.0002 | Meta Epsilon: 0.4102 | Total Train Steps: 1782048 | Time/Batch: 12.87s | Avg Time/Batch: 15.14s
Meta Batch 4060/35714 | Tasks 56840/500000 | Avg Batch Reward: 0.34 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4094 | Total Train Steps: 1786368 | Time/Batch: 14.31s | Avg Time/Batch: 14.53s
Meta Batch 4070/35714 | Tasks 56980/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4085 | Total Train Steps: 1790656 | Time/Batch: 13.56s | Avg Time/Batch: 15.42s
Meta Batch 4080/35714 | Tasks 57120/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.4076 | Total Train Steps: 1794976 | Time/Batch: 14.34s | Avg Time/Batch: 14.78s
Meta Batch 4090/35714 | Tasks 57260/500000 | Avg Batch Reward: 0.32 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.4067 | Total Train Steps: 1799360 | Time/Batch: 15.64s | Avg Time/Batch: 15.60s
Meta Batch 4100/35714 | Tasks 57400/500000 | Avg Batch Reward: 0.36 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4058 | Total Train Steps: 1803776 | Time/Batch: 12.88s | Avg Time/Batch: 15.17s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 57400) ---
Meta Batch 4110/35714 | Tasks 57540/500000 | Avg Batch Reward: 0.24 | Avg Batch Loss: 0.0003 | Meta Epsilon: 0.4049 | Total Train Steps: 1808128 | Time/Batch: 15.87s | Avg Time/Batch: 15.11s
Meta Batch 4120/35714 | Tasks 57680/500000 | Avg Batch Reward: 0.44 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.4041 | Total Train Steps: 1812416 | Time/Batch: 14.39s | Avg Time/Batch: 14.18s
Meta Batch 4130/35714 | Tasks 57820/500000 | Avg Batch Reward: 0.31 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4032 | Total Train Steps: 1816768 | Time/Batch: 15.57s | Avg Time/Batch: 14.45s
Meta Batch 4140/35714 | Tasks 57960/500000 | Avg Batch Reward: 0.39 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4023 | Total Train Steps: 1821088 | Time/Batch: 14.13s | Avg Time/Batch: 15.12s
Meta Batch 4150/35714 | Tasks 58100/500000 | Avg Batch Reward: 0.29 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.4014 | Total Train Steps: 1825504 | Time/Batch: 12.67s | Avg Time/Batch: 14.56s
Meta Batch 4160/35714 | Tasks 58240/500000 | Avg Batch Reward: 0.22 | Avg Batch Loss: 0.0006 | Meta Epsilon: 0.4005 | Total Train Steps: 1829856 | Time/Batch: 15.59s | Avg Time/Batch: 14.92s
Meta Batch 4170/35714 | Tasks 58380/500000 | Avg Batch Reward: 0.06 | Avg Batch Loss: 0.0002 | Meta Epsilon: 0.3997 | Total Train Steps: 1834240 | Time/Batch: 16.50s | Avg Time/Batch: 14.91s
Meta Batch 4180/35714 | Tasks 58520/500000 | Avg Batch Reward: 0.28 | Avg Batch Loss: 0.0007 | Meta Epsilon: 0.3988 | Total Train Steps: 1838624 | Time/Batch: 14.77s | Avg Time/Batch: 14.75s
Meta Batch 4190/35714 | Tasks 58660/500000 | Avg Batch Reward: 0.28 | Avg Batch Loss: 0.0004 | Meta Epsilon: 0.3979 | Total Train Steps: 1842944 | Time/Batch: 14.69s | Avg Time/Batch: 14.53s
Meta Batch 4200/35714 | Tasks 58800/500000 | Avg Batch Reward: 0.27 | Avg Batch Loss: 0.0008 | Meta Epsilon: 0.3970 | Total Train Steps: 1847392 | Time/Batch: 14.44s | Avg Time/Batch: 14.87s
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 58800) ---
Meta Batch 4210/35714 | Tasks 58940/500000 | Avg Batch Reward: 0.52 | Avg Batch Loss: 0.0005 | Meta Epsilon: 0.3962 | Total Train Steps: 1851712 | Time/Batch: 13.79s | Avg Time/Batch: 14.80s

训练被中断。正在保存当前检查点...Process SpawnPoolWorker-651:
Process SpawnPoolWorker-650:
Process SpawnPoolWorker-652:
Process SpawnPoolWorker-643:

Process SpawnPoolWorker-649:
Process SpawnPoolWorker-653:
Process SpawnPoolWorker-646:
Process SpawnPoolWorker-645:
Process SpawnPoolWorker-647:
Process SpawnPoolWorker-648:
Process SpawnPoolWorker-654:
Process SpawnPoolWorker-644:
Process SpawnPoolWorker-642:
Process SpawnPoolWorker-641:
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/root/rl/mpreptile.py", line 95, in reptile_worker
    states_tensor = torch.tensor(obs_np, dtype=torch.float32, device=worker_device)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/root/rl/mpreptile.py", line 101, in reptile_worker
    next_obs, rewards, terminated, truncated, info = task_env.step(actions_np)
  File "/root/miniconda3/lib/python3.10/site-packages/pogema/wrappers/metrics.py", line 16, in step
    obs, reward, terminated, truncated, infos = self.env.step(action)
  File "/root/miniconda3/lib/python3.10/site-packages/pogema/wrappers/metrics.py", line 16, in step
    obs, reward, terminated, truncated, infos = self.env.step(action)
  File "/root/miniconda3/lib/python3.10/site-packages/pogema/wrappers/metrics.py", line 16, in step
    obs, reward, terminated, truncated, infos = self.env.step(action)
  File "/root/miniconda3/lib/python3.10/site-packages/pogema/wrappers/multi_time_limit.py", line 6, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
  File "/root/miniconda3/lib/python3.10/site-packages/pogema/envs.py", line 147, in step
    infos = self._get_infos()
  File "/root/miniconda3/lib/python3.10/site-packages/pogema/envs.py", line 207, in _get_infos
    def _get_infos(self):
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/root/rl/mpreptile.py", line 98, in reptile_worker
    actions_np, new_hidden_state = task_agent.select_actions(states_tensor, current_hidden_state)
  File "/root/rl/mpreptile.py", line 410, in select_actions
    q_values, new_hidden_state = self.q_net(states, current_hidden_state)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/rl/mpreptile.py", line 284, in forward
    lstm_out, new_hidden_state = self.lstm(lstm_in, hidden_state)  # lstm_out: (B, T, Hidden Size)
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 879, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
  File "/root/rl/mpreptile.py", line 98, in reptile_worker
    actions_np, new_hidden_state = task_agent.select_actions(states_tensor, current_hidden_state)
  File "/root/rl/mpreptile.py", line 410, in select_actions
    q_values, new_hidden_state = self.q_net(states, current_hidden_state)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
KeyboardInterrupt
  File "/root/rl/mpreptile.py", line 280, in forward
    cnn_out = self.cnn(cnn_in)  # 通过CNN层 cnn_out: (B*T, Features)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/root/rl/mpreptile.py", line 98, in reptile_worker
    actions_np, new_hidden_state = task_agent.select_actions(states_tensor, current_hidden_state)
  File "/root/rl/mpreptile.py", line 410, in select_actions
    q_values, new_hidden_state = self.q_net(states, current_hidden_state)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/rl/mpreptile.py", line 288, in forward
    fc_out = self.fc_layers(fc_in)  # fc_out: (B*T, num_actions)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
KeyboardInterrupt
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
KeyboardInterrupt
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 365, in get
    res = self._reader.recv_bytes()
  File "/root/miniconda3/lib/python3.10/multiprocessing/connection.py", line 221, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/root/miniconda3/lib/python3.10/multiprocessing/connection.py", line 419, in _recv_bytes
    buf = self._recv(4)
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/connection.py", line 384, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 114, in worker
    task = get()
  File "/root/miniconda3/lib/python3.10/multiprocessing/queues.py", line 364, in get
    with self._rlock:
  File "/root/miniconda3/lib/python3.10/multiprocessing/synchronize.py", line 95, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/root/miniconda3/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 125, in worker
    result = (True, func(*args, **kwds))
  File "/root/miniconda3/lib/python3.10/multiprocessing/pool.py", line 48, in mapstar
    return list(map(*args))
  File "/root/rl/mpreptile.py", line 98, in reptile_worker
    actions_np, new_hidden_state = task_agent.select_actions(states_tensor, current_hidden_state)
  File "/root/rl/mpreptile.py", line 410, in select_actions
    q_values, new_hidden_state = self.q_net(states, current_hidden_state)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/rl/mpreptile.py", line 284, in forward
    lstm_out, new_hidden_state = self.lstm(lstm_in, hidden_state)  # lstm_out: (B, T, Hidden Size)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py", line 879, in forward
    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,
KeyboardInterrupt
--- 检查点已保存到 reptile_drqn_meta_agent_interrupt.pth (Iter: 58954) ---
检查点已保存。安全退出。
正在关闭工作进程池...
